<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css"> 
    <title>Temario PE</title>
</head>
<body>
    <h1  style="text-align: center;">Tema 1 Estadística descriptiva</h1> 

    <section> <h2>1.1 Conceptos básicos de estadística</h2>
        <ol>
            <li><n style="font-size: 20px; color: #94e468;">Definición</n><br>
                La probabilidad y estadística es la rama de las matemáticas que se ocupa de la recopilación, organización, presentación, análisis e interpretación de datos.</li>
            <li><n style="font-size: 20px; color: #94e468;">Teoría de decisión</n><br>      
                Es un campo de las matemáticas y la estadística que se ocupa de la toma de decisiones bajo incertidumbre.
            <li><n style="font-size: 20px; color: #94e468;">Población</n><br>   
                Es el conjunto completo de todos los elementos que se están estudiando en una investigación estadística.
            <li><n style="font-size: 20px; color: #94e468;">Muestra aleatoria</n><br>     
                    Es un subconjunto de la población seleccionado de tal manera que cada elemento de la población tiene la misma probabilidad de ser seleccionado.
            <li><n style="font-size: 20px; color: #94e468;">Parámetros aleatorios</n><br>  
                Son características numéricas de una distribución de probabilidad que no se conocen con certeza y deben estimarse a partir de una muestra.
                </ol>
                <p>Para una mejor compresión, se creo un Notebook que engloba los sbtemas de este primer tema: <br>
                    En <STrong>Frecuencias</STrong> puedes encontrar todos los codigos y las ejeciciones de cada ellos
                    <br><br>
        <br><center><iframe src="https://nbviewer.org/github/imac22/Frecuencias/blob/685d5fdfe6a3038fe4dfe63c0c09bedb8ac41843/numeros.ipynb" width="80%" height="800px"></iframe></center>
    <br><br>
    Aqui en             
    </p>
    </section>

    <section> <h2>1.2 Descripción de datos</h2>
        <ol>
            <li><n style="font-size: 20px; color: #94e468;">Datos agrupados y no agrupados</n><br>

            <n>Datos agrupados: </n> Son datos que han sido organizados en clases o intervalos, de manera que se agrupan los valores que se encuentran dentro de un determinado rango.<br>
            <br><n>Datos no agrupados: </n> Son datos que se presentan en su forma individual, sin agrupar en clases o intervalos.
            </li>

            <li><n style="font-size: 20px; color: #94e468;">Frecuencia de clase</n><br>      
                Es el número de veces que aparece un determinado valor o rango de valores dentro de una clase.

            <li><n style="font-size: 20px; color: #94e468;">Frecuencia relativa</n><br>   
                Es la proporción de veces que aparece un determinado valor o rango de valores dentro de una clase, expresada como un porcentaje o una fracción. Se calcula dividiendo la frecuencia de clase por el total de datos.adística.

            <li><n style="font-size: 20px; color: #94e468;">Punto medio</n><br>     
                Es el valor central de una clase, obtenido al sumar los límites inferior y superior de la clase y dividir por dos.

            <li><n style="font-size: 20px; color: #94e468;">Límites</n><br>  
                Son los valores que marcan el inicio y el final de una clase. El límite inferior es el valor más pequeño de la clase, mientras que el límite superior es el valor más grande.
                </ol>
    </section>

    <section> <h2>1.3 Medidas de tendencia central</h2>
        <ol>
            <li><n style="font-size: 20px; color: #94e468;">Media aritmética</n><br>
                Es el promedio de un conjunto de datos, obtenido al sumar todos los valores y dividir por el número total de datos. Se representa matemáticamente como:

                <p><strong>Media aritmética = (Σ xᵢ) / n</strong></p>
                <p>Donde: <br>

                    Σ representa la suma de todos los valores (xᵢ) <br>
                    n es el número total de datos</p>

            <li><n style="font-size: 20px; color: #94e468;">Media geométrica</n><br>      
                Es el promedio de un conjunto de datos, pero en lugar de sumar los valores, se multiplican y luego se extrae la raíz n-ésima del producto. Se representa matemáticamente como:
                
                <p><strong>Media geométrica: = (√[Π xᵢ])^(1/n)</strong></p>
                <p>Donde: <br>

                    Π representa la multiplicación de todos los valores (xᵢ)<br>
                    n es el número total de datos</p>

            <li><n style="font-size: 20px; color: #94e468;">Media ponderada</n><br>   
                Es el promedio de un conjunto de datos, donde cada valor se multiplica por un peso correspondiente y luego se divide por la suma de todos los pesos. Se representa matemáticamente como:
                
                <p><strong>Media ponderada: = (Σ (xᵢ * wᵢ)) / Σ wᵢ</strong></p>
                <p>Donde: <br>

                    Σ representa la suma de todos los valores (xᵢ) multiplicados por sus respectivos pesos (wᵢ) <br>
                    Σ wᵢ representa la suma de todos los pesos (wᵢ)</p>
                
            <li><n style="font-size: 20px; color: #94e468;">Mediana</n><br>     
                Valor central de un conjunto de datos ordenado de menor a mayor. Si el conjunto de datos tiene un número par de elementos, la mediana es el promedio de los dos valores centrales.
    
            <li><n style="font-size: 20px; color: #94e468;">Moda</n><br>  
                Es el valor que aparece con mayor frecuencia en un conjunto de datos. Puede haber una, dos o más modas en un conjunto de datos.

                <li><n style="font-size: 20px; color: #94e468;">Medidas de dispersión</n><br>  
                    Son herramientas que nos ayudan a cuantificar la variabilidad o dispersión de los datos en un conjunto. En otras palabras, nos indican qué tan dispersos están los datos alrededor de su valor central 


                    <li><n style="font-size: 20px; color: #94e468;">Varianza</n><br>  
                        Es el promedio del cuadrado de las desviaciones de cada valor respecto a la media aritmética. Se representa matemáticamente como:

                        <p><strong>Varianza = Σ [(xᵢ - μ)²] / n</strong></p>
                        <p>Donde: <br>
        
                            Σ representa la suma de todas las desviaciones al cuadrado [(xᵢ - μ)²] <br>
                            n es el número total de datos <br>
                            μ es la media aritmética</p>

                            <li><n style="font-size: 20px; color: #94e468;">Desviación estándar</n><br>  
                                Es la raíz cuadrada de la varianza. Se representa matemáticamente como:
        
                                <p>Desviación estándar = √Varianza</p>

                                <li><n style="font-size: 20px; color: #94e468;">Desviación media</n><br>  
                                    Es el promedio de las desviaciones absolutas de cada valor respecto a la media aritmética. Se representa matemáticamente como:
            
                                    <p> <strong>Desviación media = Σ |xᵢ - μ| / n</strong></p>

                                    <li><n style="font-size: 20px; color: #94e468;">Desviación mediana</n><br>  
                                        Es la mediana de las desviaciones absolutas de cada valor respecto a la mediana.

                                <li><n style="font-size: 20px; color: #94e468;">Rango</n><br>  
                                    Es la diferencia entre el valor máximo y el valor mínimo de un conjunto de datos.
                </ol>
    </section>

    <section> <h2>1.4 Parámetros para datos agrupados</h2>
        <p>En probabilidad, los parámetros para datos agrupados se utilizan para describir las características de una distribución de probabilidad a partir de datos que han sido agrupados en intervalos o clases. 
            Estos parámetros son útiles para analizar la distribución de la variable aleatoria sin tener que trabajar con los datos individuales. Los principales parámetros para datos agrupados son:</p> <br>

            <p><n style="font-size: 20px; color: #94e468;">Frecuencia absoluta:</n> Es el número de veces que aparece un determinado valor o rango de valores dentro de una clase. Se representa con la letra f.</p><br>

            <p><n style="font-size: 20px; color: #94e468;">Frecuencia relativa:</n> Es la proporción de veces que aparece un determinado valor o rango de valores dentro de una clase, expresada como un porcentaje o una fracción. Se calcula dividiendo la frecuencia absoluta por el total de datos. Se representa con la letra fr.</p><br>

            <p><n style="font-size: 20px; color: #94e468;">Frecuencia acumulada:</n> Es la suma de las frecuencias absolutas o relativas desde el primer intervalo hasta el intervalo que se está considerando. Se representa con las letras Fa o Fr.</p><br>

    </section>

    <section> <h2>1.5 Distribución de frecuencias</h2>
        <p> Es una forma de organizar y presentar datos cuantitativos, ya sean discretos o continuos, agrupándolos en clases o intervalos y mostrando la frecuencia con la que aparece 
            cada clase o intervalo. Es una herramienta fundamental para describir la distribución de los datos y obtener información sobre sus características principales.Elementos de una distribución de frecuencias:</p><br>

            <p><n style="font-size: 20px; color: #94e468;">Clases o intervalos:</n> Son los grupos en los que se dividen los datos. Se definen por sus límites inferior y superior.</p><br>

            <p><n style="font-size: 20px; color: #94e468;">Frecuencia absoluta:</n> Es el número de veces que aparece un dato dentro de una clase o intervalo.</p><br>

            <p><n style="font-size: 20px; color: #94e468;">Frecuencia relativa:</n> Es la proporción de veces que aparece un dato dentro de una clase o intervalo, expresada como un porcentaje o una fracción. Se calcula dividiendo la frecuencia absoluta por el total de datos.</p><br>
    </section>

    <section> <h2>1.6 Técnicas de agrupación de datos</h2>
        <p>Es el proceso de organizar y dividir un conjunto de datos en clases o intervalos, con el objetivo de facilitar su análisis y comprensión. Esta técnica es especialmente útil cuando se trabaja con grandes conjuntos de datos, ya que permite resumir la información y obtener una visión general de la distribución de los datos.
            Existen diferentes técnicas de agrupación de datos, cada una con sus propias ventajas y desventajas:</p><br>

            <p style="font-size: 20px; color: #94e468;">1. Agrupación por igual ancho de clase</p><br>

            <p>Definición: Esta técnica consiste en dividir el rango de valores en clases o intervalos que tengan el mismo ancho. <br>
                Ventajas: Es simple y fácil de implementar. <br>
                Desventajas: Puede no ser adecuada para datos con distribuciones no uniformes, ya que puede generar clases con muy pocos o demasiados datos.</p><br>

            <p style="font-size: 20px; color: #94e468;">2. Agrupación por frecuencias iguales</p><br>

            <p>Definición: Esta técnica consiste en dividir el rango de valores en clases o intervalos que contengan un número aproximadamente igual de datos. <br>
                Ventajas: Se asegura que todas las clases tengan un número similar de datos, lo que facilita la comparación. <br>
                Desventajas: Puede ser más compleja de implementar que la agrupación por igual ancho de clase y puede generar clases con anchos diferentes.</p><br>
    </section>

    <section> <h2>1.7 Técnicas de muestreo</h2>
        <p>Son procedimientos estadísticos que se utilizan para seleccionar un subconjunto de elementos (muestra) de una población más grande, con el objetivo de obtener 
            información sobre toda la población a partir del análisis de la muestra.</p> <br>

            <p style="font-size: 20px; color: #94e468;">1. Muestreo probabilístico</p><br>
            <p>En el muestreo probabilístico, cada elemento de la población tiene una probabilidad conocida y no nula de ser seleccionado para la muestra. Esto garantiza que todos los elementos tengan la misma oportunidad de ser incluidos en la muestra.</p><br>

            <p style="font-size: 20px; color: #94e468;">2. Muestreo no probabilístico</p><br>
            <p>En el muestreo no probabilístico, no se conoce la probabilidad de selección de cada elemento de la población. Esto significa que no todos los elementos tienen la misma oportunidad de ser incluidos en la muestra.</p><br>
    </section>

    <section> <h2>1.8. Histogramas</h2>
        <p>Un histograma es una representación gráfica que utiliza barras para mostrar la distribución de datos cuantitativos. Se construye dividiendo el rango de valores en intervalos o clases, y luego contando la frecuencia de datos que caen dentro de cada intervalo. 
            La altura de cada barra del histograma representa la frecuencia de datos para el intervalo correspondiente.
        <br>Son herramientas gráficas fundamentales en el ámbito de la probabilidad y la estadística, utilizados para representar la distribución de datos cuantitativos. </p> <br>
    </section>

    <h1  style="text-align: center;">Tema 2 Fundamentos de la Teoría de Probabilidad.</h1> 

    <section> <h2>2.1 Técnicas de Conteo</h2>
        <p>Sirven para calcular el número total de resultados posibles en un experimento o evento aleatorio. 
            En situaciones donde hay múltiples opciones o combinaciones posibles, estas estrategias son particularmente útiles.
        <br>
        Las técnicas de conteo generalmente se basan en principios de conteo y combinatoria fundamentales, como el principio de multiplicación, las permutaciones y las combinaciones.
    <br><br>
        Para ello, se desarrollaron ejercicios: <br><center><iframe src="https://nbviewer.org/github/imacc19/EJERCICIOS-TEMA2-PE/blob/777e76ab8618457f8e97ff1632c68d62414f43bc/Ejercicios.ipynb" width="80%" height="800px"></iframe></center>
   <br><br>
   Si necesitas revisar los codigos completos para una mejor comprensión, te los dejo aca abajo: <br><br>
<center><iframe src="https://nbviewer.org/github/imacc19/EJERCICIOS-TEMA2-PE/blob/777e76ab8618457f8e97ff1632c68d62414f43bc/codigosCompletos.ipynb" width="80%" height="800px"></iframe></center>
    </p>
    
    </section>   

    <section> <h2>2.1.1 Principio aditivo.</h2>
        <p>El Principio Aditivo es un método fundamental de conteo en Probabilidad y Estadística que se utiliza para calcular el número total de resultados posibles en situaciones en las que dos o más eventos son mutuamente excluyentes.
           Se afirma que la probabilidad de que ocurra al menos uno de dos eventos mutuamente excluyentes es igual a la suma de las probabilidades individuales de cada evento. Si dos eventos no pueden ocurrir al mismo tiempo, se consideran mutuamente excluyentes.<br>
        <br>
        Matemáticamente, el Principio Aditivo se expresa de la siguiente manera:
        <br>
        <br>
        <strong>(A o B) = P(A) + P(B)</strong>
        <br>
        <br>
<strong>Donde:</strong>

P(A o B) representa la probabilidad de que ocurra el evento A o el evento B, o ambos. <br>
P(A) representa la probabilidad de que ocurra el evento A. <br>
P(B) representa la probabilidad de que ocurra el evento B. <br>
    </p>
    <p></p>
    </section> 

    <section> <h2>2.1.2 Principio multiplicativo.</h2>
        <p>
            El Principio Multiplicativo, también conocido como Regla del Producto, es otra técnica de conteo en probabilidad y estadística que se utiliza para calcular el número total de resultados posibles cuando existen dos o más eventos independientes.
            Se utiliza cuando la ocurrencia de un evento no afecta la probabilidad de que ocurra otro evento. Esto es diferente al Principio Aditivo, que se aplica a eventos mutuamente excluyentes.
            <br>El Principio Multiplicativo afirma que la probabilidad de que ocurran dos eventos independientes es igual al producto de las probabilidades individuales de cada evento.
            <br>
        <br>
        Matemáticamente, el Principio Multiplicativo se expresa de la siguiente manera:
        <br>
        <br>
        <strong>P(A y B) = P(A) * P(B)</strong>
        <br>
        <br>
    <strong>Donde:</strong>

    P(A y B) representa la probabilidad de que ocurran el evento A y el evento B simultáneamente. <br>
    P(A) representa la probabilidad de que ocurra el evento A. <br>
    P(B) representa la probabilidad de que ocurra el evento B. <br>
    </p>
    </section> 

    <section> <h2>2.1.3 Notación Factorial.</h2>
        <p>
            Representada por el signo de exclamación <strong>"!"</strong> después de un número entero positivo, es una función matemática fundamental que se utiliza en diversas áreas de las matemáticas.
            El factorial de un número entero positivo n se define como el producto de todos los números enteros positivos desde 1 hasta n.
            <br>
        <br>
        Se expresa matemáticamente de la siguiente manera:
        <br>
        <br>
        <strong>n! = n * (n - 1) * (n - 2) * ... * 2 * 1</strong>
        <br>
        <br>
    <strong>Sus propiedades son:</strong> <br>

    Factorial de 0: El factorial de 0 se define como 1:
    0! = 1<br>
    Factorial de 1: El factorial de 1 es simplemente 1:
    1! = 1 <br>
    </section> 

    <section> <h2>2.1.4 Permutaciones.</h2>
        <p>
            Son una técnica de conteo fundamental para determinar el número total de formas distintas en que se puede ordenar un conjunto de elementos.
            <br>
            En las permutaciones, el orden importa, a diferencia de las combinaciones. En otras palabras, dos permutaciones que tienen los mismos elementos pero están ordenadas de manera diferente se consideran distintas.
            La fórmula para permutaciones es la siguiente:
        <br>
        <br>
        Se expresa matemáticamente de la siguiente manera:
        <br>
        <br>
        <strong>P_n^k = n(n - 1)(n - 2)(n - k + 1)</strong>
        <br>
        <br>
    <strong>Donde:</strong> <br>
    P_n^k representa el número de permutaciones de n elementos tomados k a la vez.<br>
    n representa el número total de elementos en el conjunto.<br>
    k representa el número de elementos que se seleccionan del conjunto para la permutación. <br>
    </section> 

    <section> <h2>2.1.5 Combinaciones.</h2>
        <p>
            Las combinaciones de probabilidad y estadística son un método de conteo que se utiliza para determinar el número total de formas distintas en que se puede seleccionar un conjunto de elementos sin importar el orden en que se seleccionan. <br>
             En las combinaciones, el orden no importa, a diferencia de las permutaciones, donde sí importa el orden. Es decir, dos combinaciones que contienen los mismos elementos pero que están ordenadas de manera diferente se consideran iguales.
            <br>
        <br>
        Se expresa matemáticamente de la siguiente manera:
        <br>
        <br>
        <strong>P_n^k = n(n - 1)(n - 2)(n - k + 1)</strong>
        <br>
        <br>
    <strong>Donde:</strong> <br>

    P_n^k representa el número de permutaciones de n elementos tomados k a la vez.<br>
    n representa el número total de elementos en el conjunto.<br>
    k representa el número de elementos que se seleccionan del conjunto para la permutación. <br>
    </section> 

    <section> <h2>2.1.6 Diagrama de Árbol.</h2>
        <p>
        Las probabilidades de eventos compuestos o secuenciales se pueden representar y calcular utilizando un diagrama de árbol. Es una forma visual de organizar y analizar las diversas posibilidades que pueden ocurrir en un experimento o situación aleatoria.
    <br><br>
    <strong>La estructura de un diagrama de árbol es la siguiente:</strong>
    <br><br>
        Un diagrama de árbol tiene <strong>ramas y nodos.</strong> Las ramas representan los diversos resultados potenciales de un evento o decisión. Los puntos de decisión o eventos en el proceso se denominan nodos. Cada rama que sale de un nodo representa una posibilidad particular que surge de ese evento.
            <br>
        <br>
        <strong>En un diagrama de árbol, las probabilidades son:</strong> <br><br>
        En el diagrama de árbol, se le asigna una probabilidad a cada rama, que representa la probabilidad de que ese resultado específico ocurra. Las reglas de probabilidad, 
        como la regla de la suma y la regla del producto, se utilizan para calcular las probabilidades.
        <br>
        <br>
        <strong>2.1.7 Teorema del Binomio.</strong>
        <br>
        <br>
    <strong>Donde:</strong> <br>

    Lanzamiento 1: <br>
    Cara (C) -> Lanzamiento 2: Cara (C) = CC (Probabilidad: 1/4) <br>
        -> Lanzamiento 2: Cruz (X) = CX (Probabilidad: 1/4) <br>
    Cruz (X) -> Lanzamiento 2: Cara (C) = XC (Probabilidad: 1/4) <br>
        -> Lanzamiento 2: Cruz (X) = XX (Probabilidad: 1/4) <br>
    </section> 

    <section> <h2>2.1.6 Diagrama de Árbol.</h2>
        <p>
        Las probabilidades de eventos compuestos o secuenciales se pueden representar y calcular utilizando un diagrama de árbol. Es una forma visual de organizar y analizar las diversas posibilidades que pueden ocurrir en un experimento o situación aleatoria.
    <br><br>
    <strong>La estructura de un diagrama de árbol es la siguiente:</strong>
    <br><br>
        Un diagrama de árbol tiene <strong>ramas y nodos.</strong> Las ramas representan los diversos resultados potenciales de un evento o decisión. Los puntos de decisión o eventos en el proceso se denominan nodos. Cada rama que sale de un nodo representa una posibilidad particular que surge de ese evento.
            <br>
        <br>
        <strong>En un diagrama de árbol, las probabilidades son:</strong> <br><br>
        Se le asigna una probabilidad a cada rama, que representa la probabilidad de que ese resultado específico ocurra. Las reglas de probabilidad, 
        como la regla de la suma y la regla del producto, se utilizan para calcular las probabilidades.
        <br>
        <br>
        <strong>Ejemplo de un diagrama de árbol:</strong>
        <br>
        <br>
    <strong>Donde:</strong> <br>

    Ejemplo de un lanzamiento de moneda: <br>
    Cara (50%) -----> Lanzamiento 1
                      | Cara (50%) --> Cara (25%) <br>
                      | Cruz (50%)  --> Cruz (25%)<br>
  Cruz (50%) -----> Lanzamiento 2 <br>
                      | Cara (50%) --> Cruz (25%) <br>
                      | Cruz (50%)  --> Cara (25%)<br>
    </section>

<section> 
    <h2>2.1.7 Teorema del Binomio.</h2>
        <p>
            Es una fórmula fundamental para explicar la distribución de probabilidades en experimentos aleatorios binomiales.
            Las siguientes características definen un experimento binomial: <br>

           <strong>Hay dos posibilidades de resultados:</strong>  El experimento solo produce dos resultados posibles: <strong>"éxito"</strong> y <strong>"fracaso".</strong> <br> <br>
            
        <strong>Eventos independientes:</strong> Los resultados de los eventos posteriores no se ven afectados por los resultados de cada evento en particular. <br> <br>
            
    <strong>Número finito de repeticiones:</strong> el experimento se repite una cantidad determinada de veces, generalmente representada por la letra <strong>"n".</strong> <br> <br>
            
    <br><br>
    <strong>La formula para calcular la probabilidad de obtener "k" éxitos en "n" repeticiones es la siguiente:</strong>
    <br><br>
    <strong></strong>P(k éxitos) =  nCk * (p^k) * (q^(n-k))</strong> <br>
        <br>
        <strong>Donde:</strong> <br><br>
        P(k éxitos): Representa la probabilidad de obtener "k" éxitos en "n" repeticiones.
nCk: Es el coeficiente binomial, que representa el número de combinaciones posibles de "k" elementos de un conjunto de "n" elementos. 
    </section>

<section><h2>2.2 Teoría elemental de probabilidad</h2>

    <p>Una rama fundamental del campo de la probabilidad es la teoría elemental de la probabilidad,
         también conocida como probabilidad clásica. Se basa en la idea de que la probabilidad de un 
         evento se puede calcular como la proporción de resultados favorables entre todos los resultados 
         posibles igualmente probables. <br> <br>

         <strong>La probabilidad de un evento (A) se define como:</strong> <br> <br>

         <strong>P(A) = n(A) / n(S)</strong><br><br>

        <strong>Donde:</strong><br><br>

    <strong>P(A):</strong> Representa la probabilidad del evento A. <br>
    <strong>n(A):</strong> Es el número de resultados favorables al evento A. <br>
    <strong>n(S):</strong> Es el número total de resultados posibles igualmente probables del experimento aleatorio. <br>
    </p>
</section>

    <section><h2>2.3 Probabilidad de Eventos </h2>
        <p>
            La probabilidad de un evento se define como la medida numérica que indica la probabilidad o la certeza de que ese evento ocurra en un experimento aleatorio. <br>
La probabilidad de un evento se calcula como la proporción de los resultados favorables al evento dentro del espacio muestral. El conjunto muestral o espacio muestral es el conjunto de todos los resultados posibles del experimento aleatorio.
        </p>

        <li><n style="font-size: 20px; color: #94e468;">Espacio muestral</n><br>
            <p>El espacio muestral, también conocido como espacio muestral o conjunto muestral, 
                es el conjunto de todos los resultados posibles de un experimento aleatorio en el
                campo de la probabilidad y la estadística. La letra <strong>Ω</strong> (omega) o la letra E suelen ser sus representaciones.
                <br>
                <br>
                <strong>Algunas características son:</strong>
        <strong>Completitud:</strong> El espacio muestral debe incluir todos los resultados posibles del experimento, sin omitir ninguno. <br>
        <strong>Exclusividad:</strong> Los resultados del espacio muestral deben ser mutuamente excluyentes, es decir, la ocurrencia de un resultado excluye la posibilidad de que ocurran los demás. <br>
        <strong>Unión:</strong> La unión de todos los resultados del espacio muestral debe abarcar todo el espacio muestral en sí mismo. <br>
   <br>
   <br>
    </p>
    <p>
        <li><n style="font-size: 20px; color: #94e468;">Definición de evento</n><br> <br>
            Un evento se define como un conjunto específico de resultados posibles dentro de un experimento aleatorio. Mayormente se representa con letras mayúsculas en matemáticas.
    </p>

    <p>
        <li><n style="font-size: 20px; color: #94e468;">Simbología</n><br> <br>
            La simbología es esencial para representar conceptos, fórmulas y resultados de manera concisa y clara. Aquí hay un resumen de algunos de los símbolos más utilizados en estadística y probabilidad: <br> <br>

        <strong>P(E):</strong> Probabilidad del evento E. Representa la medida numérica de la posibilidad de que ocurra el evento E en un experimento aleatorio. <br>

        <strong>n(E):</strong> Número de resultados favorables al evento E. Representa la cantidad de outcomes dentro del espacio muestral que cumplen con la definición del evento E. <br>

        <strong>n(Ω):</strong> Número total de resultados posibles en el espacio muestral (Ω). Representa la cantidad total de outcomes que pueden ocurrir en el experimento aleatorio. <br>

        <strong>Ω:</strong> Espacio muestral. Representa el conjunto de todos los resultados posibles del experimento aleatorio. <br>

        <strong>A ∪ B:</strong> Unión de los eventos A y B. Representa el conjunto de outcomes que pertenecen a A, a B o a ambos. <br>

        <strong>A ∩ B:</strong> Intersección de los eventos A y B. Representa el conjunto de outcomes que pertenecen a ambos eventos, A y B. <br>

        <strong>A':</strong> Evento complementario de A. Representa el conjunto de outcomes del espacio muestral que no pertenecen al evento A. <br>

        <strong>X:</strong> Variable aleatoria. Representa una característica o atributo que puede tomar diferentes valores aleatorios en un experimento. <br>

        <strong>x:</strong> Valor específico de la variable aleatoria X. Representa un outcome particular que puede tomar la variable aleatoria. <br> <br>
    </p>

    <p>
        <li><n style="font-size: 20px; color: #94e468;">Unión</n><br> <br>
            La unión de eventos es una operación matemática que combina dos o más eventos para formar un evento más grande. 
    </p>

    <p>
        <li><n style="font-size: 20px; color: #94e468;">Intersección</n><br> <br>
        La intersección de eventos es una operación matemática que combina dos o más eventos en un solo evento más limitado. El símbolo "∩" se usa para representarlo.

    </p>

    <p>
        <li><n style="font-size: 20px; color: #94e468;">Diagramas de Venn</n><br> <br>
        Los diagramas de Venn son una herramienta gráfica para representar las relaciones entre conjuntos de elementos o eventos.
         Se basan en la ilustración de las diferentes posibilidades de resultados en un experimento aleatorio mediante la superposición de círculos o figuras geométricas.
    </p>
    </section>

    <section><h2>2.4 Probabilidad con Técnicas de Conteo</h2>
        <p>
            Las técnicas de conteo de probabilidad utilizan técnicas de conteo básicas para calcular la probabilidad de que sucedan eventos en experimentos aleatorios. Cuando la definición del evento de interés y el espacio muestral (conjunto de todos los resultados posibles) son relativamente simples y permiten una enumeración clara de los resultados, estos métodos son particularmente útiles.
        </p> <br> <br>
        <p>
            <li><n style="font-size: 20px; color: #94e468;">Axiomas</n><br>
                Los axiomas son un conjunto de principios fundamentales que sirven como base para la definición y el cálculo de probabilidades. Estos axiomas se consideran verdades autoevidentes que permiten construir una teoría de probabilidad sólida y consistente, no pruebas empíricas.
        </p>
        <p>
            <li><n style="font-size: 20px; color: #94e468;">Teoremas</n><br>
            Los teoremas son afirmaciones o proposiciones matemáticas que se deducen de los axiomas y principios fundamentales de la teoría. Estos teoremas brindan herramientas para analizar y comprender el comportamiento de fenómenos aleatorios y establecen las relaciones entre variables aleatorias, eventos y distribuciones de probabilidad.
            <br>
            La teoría y sus aplicaciones dependen de los teoremas de probabilidad y estadística. Permiten realizar inferencias estadísticas, formular modelos probabilísticos y tomar decisiones informadas en situaciones de incertidumbre.
        </p>
    </section>

    <section><h2>2.5 Probabilidad condicional</h2>
        <p>
            Una herramienta clave en la teoría de la probabilidad es la probabilidad condicional, también conocida como probabilidad a posteriori o probabilidad Bayesiana. Permite calcular la probabilidad de un evento porque ya ha ocurrido otro evento. En otras palabras, la probabilidad condicional describe la probabilidad de que un evento ocurra teniendo en cuenta la información adicional de que ya ha ocurrido un evento.
        </p> <br>
        <p>
            <li><n style="font-size: 20px; color: #94e468;">Dependiente</n><br>
            Es una situación en la que la probabilidad de un evento se ve afectada por la información sobre la ocurrencia o no ocurrencia de otro evento. Esta dependencia es importante para modelar situaciones en las que la probabilidad de un evento no es constante y cambia en función de otros eventos.
        </p>
        <p>
            <li><n style="font-size: 20px; color: #94e468;">Independiente</n><br>
            Es una situación en la que la información sobre la ocurrencia o no ocurrencia de un evento no afecta la probabilidad de otro evento. Esta propiedad es fundamental para modelar situaciones en las que los eventos no se influencian mutuamente y ocurren de manera aleatoria e independiente.
        </p>
    </section>

    <section><h2>2.6 Ley multiplicativa</h2>
        <p>
            Es un concepto fundamental que permite calcular la probabilidad de que dos o más eventos se intersecten.
        <br> <br>
       <strong>La ley multiplicativa se expresa matemáticamente mediante la siguiente fórmula:</strong> <br><br>
            <strong>P(A ∩ B) = P(A) * P(B | A)</strong> <br> <br>

            <strong>Donde:</strong> <br> <br>
            <strong>P(A ∩ B):</strong> Probabilidad de la intersección de los eventos A y B. La intersección representa la ocurrencia simultánea de ambos eventos. <br>
            <strong>P(A):</strong> Probabilidad del evento A sin considerar la información de B. <br>
            <strong>P(B | A):</strong> Probabilidad condicional de B dado A. Representa la probabilidad de que B ocurra sabiendo que A ya ha ocurrido.
    </p>     
    </section>

    <section><h2>2.7 Eventos independientes</h2>
        <p>
         Los eventos en los que la ocurrencia de uno no afecta la probabilidad de que ocurra el otro se denominan eventos independientes en probabilidad y estadística. En otras palabras, la información sobre si un evento ha ocurrido o no ofrece información adicional sobre la probabilidad de que ocurra otro evento.
        </p>
        <p><li><n style="font-size: 20px; color: #94e468;">Regla de Bayes</n><br>
            Es una idea clave en la teoría de la probabilidad y la estadística que permite actualizar la probabilidad de un evento basándose en datos nuevos. Es una herramienta importante para el razonamiento bajo incertidumbre y tiene una amplia gama de usos en una variedad de campos.
<br><br>
<strong>La Regla de Bayes se expresa matemáticamente mediante la siguiente fórmula:</strong> <br> <br>
<strong>P(H | E) = (P(E | H) * P(H)) / P(E)</strong><br><br>
<strong>Donde:</strong><br><br>
<strong>P(H | E):</strong> Probabilidad posterior de la hipótesis H dado el evento E. Representa la probabilidad actualizada de H después de considerar la nueva evidencia E. <br>

<strong>P(E | H):</strong> Verosimilitud del evento E dado la hipótesis H. Representa la probabilidad de observar el evento E si la hipótesis H es cierta. <br>

<strong>P(H):</strong> Probabilidad a priori de la hipótesis H. Representa la creencia o probabilidad inicial de H antes de considerar cualquier evidencia. <br>

<strong>P(E):</strong> Probabilidad total del evento E. Representa la probabilidad de observar el evento E, independientemente de que H sea cierta o falsa. <br>
        </p>
    </section>

    <h1  style="text-align: center;">Tema 3 Variables Aleatorias</h1> 

    <section> <h2>3.1 Variables aleatorias discretas</h2>
        
        <p>Son aquellas que solo pueden tomar un conjunto de valores finitos o infinitos. Las variables discretas solo pueden tomar valores específicos, como números enteros o valores contados, a diferencia de las variables aleatorias continuas, que pueden tomar cualquier valor dentro de un intervalo.</p>
        <p><strong>Algunos ejemplos claros son:</strong> <br> <br>
            La talla de una camiseta en una tienda de ropa (S, M, L, XL) <br>

            El número de caras obtenidas al lanzar una moneda (0 o 1).
         </p>
    </section>

    <section>
        <h2>3.1.1 Distribución de probabilidad en forma general</h2>
        <p>Es una función matemática que asigna la probabilidad de que ocurra un evento posible en un experimento aleatorio. La distribución de probabilidad proporciona una descripción detallada del comportamiento de la variable aleatoria que representa el resultado del experimento.
        <br><br>
        <strong>Elementos clave de una distribución de probabilidad</strong> <br> <br>

    <strong>Conjunto de eventos:</strong> El conjunto de eventos posibles en el experimento aleatorio. <br>
    <strong>Función de probabilidad:</strong> Una función que asigna a cada evento en el conjunto de eventos su probabilidad correspondiente. La suma de las probabilidades para todos los eventos debe ser igual a 1. <br>
    <strong>Función de distribución:</strong> Una función que indica la probabilidad de que la variable aleatoria sea menor o igual a un valor específico. <br>
<p>Para ello, se creo un video donde todos estos subtemas que veremos a continuación son explicados para una mejor comprensión: <a href=" https://youtu.be/7MbPGfX9iNA">PULSA AQUI</a></p>
        </p>
    </section>

    <section>
        <h2>3.1.2 Valor esperado</h2>

        <p>
            Representa el promedio ponderado de todos los posibles valores de una variable aleatoria, donde cada valor se pondera por su probabilidad de ocurrencia.
            <br> <br>
            Matemáticamente, el valor esperado de una variable aleatoria discreta <strong>X</strong>, denotado por <strong>E(X)</strong>, se calcula como la suma del producto de cada valor posible <strong>(x)</strong> de <strong>X</strong> por su probabilidad correspondiente <strong>(P(x)):</strong>
            <br> <br>
            <strong>E(X) = Σ x * P(x)</strong>
            <br><br>
    <strong>Las características mas importantes son: </strong> <br> <br>
    El valor esperado nos indica el resultado promedio que se espera obtener al realizar el experimento aleatorio un gran número de veces. <br>
    Es una medida de tendencia central de la distribución de probabilidad de la variable aleatoria. <br>
    Se utiliza en diversos campos, como la estadística, la economía, la física y la ingeniería, para analizar el comportamiento de sistemas aleatorios. <br>
        </p>
    </section>

    <section>
        <h2>3.1.3 Variancia, desviación estándar</h2>
        <p>La varianza mide cuánto se dispersan los valores de una variable aleatoria alrededor de su media. Se calcula como el promedio de los cuadrados de las diferencias entre cada valor y la media.</p>
        <p>Para una variable aleatoria discreta <strong>X</strong> con posibles valores (x1,x2) y probabilidades correspondientes. P(X=x 1),P(X=x 2 ). La varianza se calcula como: <br><br>
            <strong>Varianza (σ²) = Σ [(xi - μ)²] / n</strong> <br> <br>

            <strong>Donde:</strong> <br><br>
        <strong>xi</strong> es el valor individual de cada dato. <br>
        <strong>μ</strong> es la media del conjunto de datos. <br>
        <strong>n</strong> es el número total de datos.
        </p> <br> <br> <br>
        <p>La desviación estándar indica, en promedio, cuánto se desvían los valores de la variable aleatoria respecto a su media. Es una medida comúnmente utilizada para evaluar la variabilidad en un conjunto de datos. Se calcula:
            <br> <br>
            <strong>Desviación estándar (σ) = √Varianza (σ²)</strong>
        </p>
    </section>

    <section>
        <h2>3.1.4 Función acumulada</h2>

        <p>La función de distribución acumulada (FDA), también conocida como función de probabilidad acumulada (F), muestra la probabilidad de que una variable aleatoria X sea menor o igual a un valor específico X. En otras palabras, la FDA nos indica cuántas personas en la población tienen valores menores o iguales a x.
        <br> <br>
        <strong>Se define como:</strong> <br> <br>
        F(x) = P(X ≤ x) <br>
        Donde P(X ≤ x) representa la probabilidad del evento "X es menor o igual que x".
        </p>
    </section>

    <section>
        <h2>3.2 Variables aleatorias Continuas</h2>
        <p>A diferencia de las variables aleatorias discretas, que solo pueden tomar valores específicos, esta puede tomar cualquier valor dentro de un intervalo (o colección de intervalos). En teoría, los valores de una variable aleatoria continua son incontables y están presentes en el conjunto de números reales.</p>
        <p>Para ello, se creo un video donde, los subtemas que veremos a continuación son explicados para una mejor comprensión: <a href="https://www.youtube.com/watch?v=GFZM5CntP8g">PULSA AQUI</a></p>
    </section>

    <section>
        <h2>3.2.1 Distribución de probabilidad en forma general</h2>
        <p>Es una función matemática que describe la probabilidad de que una variable aleatoria tome cada uno de sus posibles valores. En otras palabras, la distribución de probabilidad nos proporciona la distribución de frecuencias con la que cada valor posible de la variable aleatoria puede ocurrir.</p>
        <p>
            <strong>Las distribuciones de probabilidad se pueden representar gráficamente mediante:</strong> <br> <br>
        <strong>Histogramas:</strong> Para variables aleatorias discretas, muestran la frecuencia de cada valor posible. <br>
        <strong>Curvas de densidad de probabilidad:</strong> Para variables aleatorias continuas, muestran la probabilidad por unidad de intervalo de que la variable aleatoria tome un valor dentro de un intervalo específico. <br>
        <strong>Funciones de distribución acumulada:</strong> Muestran la probabilidad de que la variable aleatoria sea menor o igual que un valor específico.</p>
    </section>

    <section>
        <h2>3.2.2 Valor esperado</h2>
        <p>El valor esperado de una variable aleatoria continua X, denotado por E(X), se calcula como la integral definida del producto de cada valor posible (x) de X por su función de densidad de probabilidad (f(x)) en el intervalo donde X puede tomar valores:
<br> <br>
        <strong>E(X) = ∫_a^b x * f(x) dx</strong> <br> <br>
        <strong>Donde:</strong> <br> <br>

a y b son los límites del intervalo donde X puede tomar valores. <br>
f(x) es la función de densidad de probabilidad de X, que representa la probabilidad por unidad de intervalo de que X tome un valor dentro de un intervalo específico.
        </p>
    </section>

    <section>
        <h2>3.2.3 Variancia, desviación estándar.</h2>
        <p>En el caso de variables aleatorias continuas, la varianza y la desviación estándar se calculan de manera similar a las variables aleatorias discretas, pero utilizando integrales en lugar de sumas. Ambas medidas nos ayudan a cuantificar la dispersión o variabilidad de los valores de la variable aleatoria alrededor de su valor esperado.</p>
        <br> <br>
        <p>La varianza (σ2) de una variable aleatoria continua llamada Var(X) se encuentra como la integral definida del cuadrado de la desviación de cada valor posible (x) de X respecto al valor esperado (E(X)) multiplicado por su función de densidad de probabilidad (f(x) en el intervalo donde X puede tener valores.</p>
        <br><br>
        <p><strong>Var(X) = σ² = ∫_a^b (x - E(X))² * f(x) dx</strong> <br> <br>

            <strong>Donde:</strong> <br> <br>
            
            a y b son los límites del intervalo donde X puede tomar valores. <br>
            E(X) es el valor esperado de X, calculado previamente. <br>
            f(x) es la función de densidad de probabilidad de X.</p>

            <br><br><br>
            <p>La desviación estándar (σ) de una variable aleatoria continua X se calcula como la raíz cuadrada de la varianza:</p>
<br>
            <strong>σ = √Var(X) = √∫_a^b (x - E(X))² * f(x) dx</strong> <br><br>
            <p><strong>Donde:</strong> <br> <br>

                a y b representan los límites de altura mínima y máxima posibles para los estudiantes en la clase. <br>
                E(X) es el valor esperado de la altura de los estudiantes, calculado previamente. <br>
                f(x) es la función de densidad de probabilidad de la distribución normal que describe la distribución de alturas de los estudiantes.</p>
    </section>

    <section>   
        <h2>3.2.4 Función acumulada</h2>
        <p>
            La función de distribución acumulada (FDA), también conocida como función de probabilidad acumulada (F), muestra la probabilidad de que una variable aleatoria continua X sea menor o igual a un valor específico x. En otras palabras, la FDA nos proporciona la cantidad de personas en la población para las que la variable aleatoria tiene valores que son iguales o menores a x.
        <br> <br>
        <strong>F(x) = P(X ≤ x)</strong> <br> <br>

        <strong>Donde:</strong> <br> <br>
        P(X ≤ x) representa la probabilidad del evento "X es menor o igual que x".
        </p>
    </section>

    <section>
        <h2>3.2.5 Cálculos de probabilidad</h2>

        <p>Los cálculos de probabilidad son una forma de calcular la probabilidad de que ocurra un evento o conjunto de eventos. La probabilidad cuantifica la incertidumbre y se representa con números de 0 a 1 que indican que el evento no puede ocurrir y el evento ciertamente ocurrirá. Los cálculos de probabilidad se utilizan en una variedad de campos, incluyendo estadística, ciencias, ingeniería, economía, juegos de azar y mucho más. 
<br> <br>
Para un espacio muestral finito, si todos los resultados son igualmente probables, la probabilidad de un evento se define como: <br> <br>
<strong><n style="font-size: 20px; color: #94e468;">Probabilidad Clásica</n></strong>
        </p>
        <p><math xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>P</mi><mo>(</mo><mi>E</mi><mo>)</mo><mo>=</mo><mfrac>
            <mrow>
                <mo>|</mo><mi>E</mi><mo>|</mo>
            </mrow>
            <mrow>
                <mo>|</mo><mi>S</mi><mo>|</mo>
            </mrow>
            </mfrac>
        </math></p>

        <strong><n style="font-size: 20px; color: #94e468;">Regla de la Suma</n></strong> <br>
    <p>Para eventos mutuamente excluyentes (que no pueden ocurrir simultáneamente):</p>
    <p><math xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>P</mi><mo>(</mo><mi>A</mi><mo>∪</mo><mi>B</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo><mo>+</mo><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo>
    </math></p>

    <strong><n style="font-size: 20px; color: #94e468;">Regla del Producto</n></strong>  <br>
    <p>Para eventos independientes (la ocurrencia de uno no afecta la ocurrencia del otro):</p>
    <p><math xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>P</mi><mo>(</mo><mi>A</mi><mo>∩</mo><mi>B</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo><mo>·</mo><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo>
    </math></p>

    <strong>Teorema de Bayes</strong> <br>
    <p><n style="font-size: 20px; color: #94e468;">Relaciona las probabilidades condicionales de dos eventos:</n></p>
    <p><math xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>P</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>)</mo><mo>=</mo><mfrac>
        <mrow>
            <mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo><mo>·</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo>
        </mrow>
        <mrow>
            <mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo>
        </mrow>
    </mfrac></math></p>

    <strong><n style="font-size: 20px; color: #94e468;">Varianza para Variables Aleatorias Continuas</n></strong><br>
    <p>Para una variable aleatoria continua <i>X</i> con una función de densidad de probabilidad <i>f(x)</i> y un valor esperado <i>E(X)</i>, la varianza <i>Var(X)</i> se define como:</p>
    <p><math xmlns="http://www.w3.org/1998/Math/MathML">
        <mi>Var</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mi>E</mi><mo>[</mo><mo>(</mo><mi>X</mi><mo>-</mo><mi>E</mi><mo>(</mo><mi>X</mi><mo>)</mo><msup><mo>)</mo><mn>2</mn></msup><mo>]</mo><mo>=</mo>
        <msub><mo>∫</mo><mrow><mo>-∞</mo></mrow><mrow><mo>∞</mo></mrow></msub><mo>(</mo><mi>x</mi><mo>-</mo><mi>E</mi><mo>(</mo><mi>X</mi><mo>)</mo><msup><mo>)</mo><mn>2</mn></msup><mo>·</mo><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>dx</mo>
    </math></p>

    <strong><n style="font-size: 20px; color: #94e468;">Desviación Estándar para Variables Aleatorias Continuas</n></strong><br>
    <p>La desviación estándar es la raíz cuadrada de la varianza. Si <i>X</i> es una variable aleatoria continua con una varianza <i>Var(X)</i>, la desviación estándar <i>σ<sub>X</sub></i> se define como:</p>
    <p><math xmlns="http://www.w3.org/1998/Math/MathML">
        <msub><mi>σ</mi><mi>X</mi></msub><mo>=</mo><msqrt>
        <mi>Var</mi><mo>(</mo><mi>X</mi><mo>)</mo>
    </msqrt></math></p>
    </section>
    
    
        <h1  style="text-align: center;">Tema 4 Distribuciones de Probabilidad</h1>      
    <section>

    <h2>4.1 Función de probabilidad.</h2>
    <p>
Es una herramienta esencial para explicar cómo se comportan las variables aleatorias discretas. Asignar una probabilidad a cada uno de los valores potenciales que puede tomar dicha variable es su principal objetivo.
<br>
La función de probabilidad es una función matemática que asocia una probabilidad entre 0 y 1 a cada resultado posible de un experimento aleatorio (contenido en el espacio muestral). Esta probabilidad es la certeza o la posibilidad de que ocurra dicho resultado.
<p>Para entender este tema de una mejor manera, se desarrollo el siguiente video donde explicaremos un ejempplo de distribuciones: <a href="https://youtu.be/7ADxsx-HXHA?si=gBSDxaKeCrnPGP7y">Pulsa Aqui</a></p> 
</p>
    </section>

    <section>
    <h2>4.2 Distribución binomial.</h2>
    <p>
        Describe la probabilidad de obtener un número específico de éxitos en un conjunto de n experimentos independientes, cada uno de los cuales tiene dos resultados potenciales: éxito o ineficacia
        <br><br>Las siguientes condiciones deben cumplirse para que se utilice la distribución binomial: <br> <br>

        <strong>Número fijo de experimentos:</strong> debe saber cuántos experimentos (n) se llevarán a cabo. <br>
        <strong>Probabilidad constante de éxito:</strong> Para cada experimento, la probabilidad de éxito (p) debe ser constante. En otras palabras, la probabilidad de obtener un éxito en un experimento individual debe ser igual para todos los experimentos. <br> 
        <br>Cada experimento debe producir dos resultados potenciales, conocidos como "éxito" y "fracaso".
    </p>
    </section>
    <section>
        <h2>4.3 Distribución hipergeométrica</h2>
        <p>
            Es una distribución de probabilidad discreta que se utiliza para modelar el número de éxitos en una muestra sin reemplazo de tamaño n extraída de una población finita de tamaño N, en la que cada elemento de la población puede ser clasificado como éxito o fracaso.
<br> <br>
            La distribución hipergeométrica asume que los experimentos no son independientes y no hay reemplazo de los elementos extraídos, a diferencia de la distribución binomial, que asume experimentos independientes con reemplazo. Esto implica que la probabilidad de éxito de cada experimento cambia a medida que se extraen elementos de la población.       
        <br><br>
        Las siguientes condiciones son necesarias para que se aplique la distribución hipergeométrica: <br> <br>

        <strong>La población finita</strong> (N) es la población de la que se extrae la muestra. <br>

    <strong>Muestreo sin reemplazo:</strong> la probabilidad de éxito cambia con cada extracción porque los elementos extraídos de la población no se reemplazan.



        </p>
    </section>

    <section>
        <h2>4.4 Distribución de Poisson</h2>
        <p>
            Es una distribución discreta que representa la cantidad de eventos que ocurren en un intervalo fijo de tiempo o espacio, suponiendo que estos eventos ocurren independientemente entre sí y con una tasa promedio constante.
<br>
            La distribución de Poisson se utiliza para modelar situaciones donde los eventos pueden ocurrir en un continuo, como el tiempo o el espacio. Se utiliza para experimentos con un número finito de ensayos.
            <br><br>
            Las siguientes condiciones deben cumplirse para que se aplique la distribución de Poisson: <br> <br>

<strong>Eventos aleatorios:</strong> Los eventos modelados deben ser aleatorios, lo que significa que su ocurrencia no puede ser determinada con certeza.

<strong>Independencia:</strong> Los eventos deben ser independientes entre sí, es decir, la probabilidad de que ocurra un evento no afecta la probabilidad de que ocurra otro evento.

<strong>Tasa constante:</strong> La tasa promedio de ocurrencia de eventos debe permanecer constante a lo largo del intervalo de tiempo o espacio.

<strong>Eventos raros:</strong> es muy poco probable que un evento ocurra en un intervalo de tiempo o espacio muy pequeño.
        </p>
    </section>

    <section>
        <h2>4.5 Distribución normal.</h2>
        <p>
            Es una de las distribuciones de probabilidad de variable continua más significativas en términos de probabilidad y estadística. Su forma es como una campana simétrica, con la mayoría de los datos agrupados alrededor de un valor central, también conocido como media, y los valores menos probables se encuentran en los extremos.
<br><br>
La distribución normal tiene las siguientes características principales: <br><br>

 <strong>Simetría:</strong> La distribución normal es simétrica en comparación con su media (μ). Esto implica que la probabilidad de que un valor esté por debajo de la media es igual a la probabilidad de que esté por encima de la media. <br>

<strong>Curva en forma de campana:</strong> La forma de distribución normal tiene una forma similar a una campana, con una concentración de datos que disminuye gradualmente hacia los extremos y alrededor de la media. <br>

<strong>Desviación estandar:</strong> La desviación estándar (σ) es una medida de la dispersión de los datos en relación con la media. Los datos serán más dispersos cuanto mayor sea la desviación estándar.
<br>
<strong>Puntos de inflexión:</strong> La curva de la distribución normal tiene dos puntos de inflexión a una distancia de ±1 desviación estándar de la media.
        </p>
    </section>

    <section> <h2>4.6 Distribución T-student</h2>
        <p>
            Es una distribución de probabilidad continua que surge del problema de estimar la media de una población normalmente distribuida cuando la muestra es pequeña y la desviación estándar de la población es desconocida.
        </p>
    </section>

    <section>
        <h2>4.7 Distribución Chi cuadrada</h2>
        <p>
            Es una distribución de probabilidad continua que se usa principalmente en estadística para realizar pruebas de hipótesis y análisis de datos. Su forma asimétrica a la derecha lo distingue y se puede usar en situaciones en las que se comparan los valores observados con los valores esperados.
<br><br>
Las características principales de la distribución chi-cuadrada son: <br> <br>

<strong>Asimetría:</strong> La distribución chi-cuadrada es asimétrica a la derecha, lo que significa que la mayoría de los valores están en el lado izquierdo de la distribución y los valores extremos están en la cola derecha. <br>
<strong>Valores posibles:</strong> La distribución chi-cuadrada solo acepta valores que no son negativos y que van desde cero hasta infinito.
        </p>
    </section>

    <section>
        <h2>4.8 Distribución F</h2>
        <p>
            Es una distribución de probabilidad continua que se utiliza principalmente en estadística para pruebas de hipótesis y análisis de varianza. Su forma asimétrica a la derecha lo hace útil en situaciones en las que se comparan las variaciones de dos muestras aleatorias.
<br><br>
Las propiedades clave de la distribución F son: <br><br>

<strong>Asimetría:</strong> La distribución F es asimétrica a la derecha, lo que significa que la mayoría de los valores se concentran en el lado izquierdo de la distribución y los valores extremos se ubican en la cola derecha.
<br>
<strong>Grados de libertad:</strong> La forma de la distribución F depende de dos parámetros conocidos como grados de libertad (gl).
        </p>
    </section>

    <h1  style="text-align: center;">Tema 5 Regresión lineal</h1> 
    <section>
        <h2>5.1 Regresión y correlación</h2>
<p>
    La regresión y la correlación son dos conceptos fundamentales para analizar la relación entre variables. Si bien a menudo se utilizan de manera conjunta, es importante comprender sus diferencias y aplicaciones específicas. 
<br><br><strong>La correlación:</strong>
<br><br>
La correlación mide la fuerza y dirección de la asociación entre dos variables. <br>
Un coeficiente de correlación positivo indica una correlación positiva, lo que significa que las variables suelen aumentar o disminuir juntas. <br>
Un coeficiente de correlación negativo indica una correlación negativa, lo que significa que las variables suelen moverse en direcciones opuestas. <br>
No hay una correlación lineal entre las variables, según un coeficiente de correlación cero.<br>

<br><br>
<strong>La regresión:</strong><br><br>
La regresión es un conjunto de métodos estadísticos que se utilizan para representar la relación entre una variable dependiente (que se quiere predecir) y una o más variables independientes. <br>
La ecuación que representa el modelo de regresión muestra cómo las variables independientes afectan a la variable dependiente.
</p>
    </section>

<section>
    <h2>5.1.1 Diagrama de dispersión</h2>
    <p>Un diagrama de dispersión, también conocido como gráfico de puntos o nube de puntos, es una herramienta gráfica que se utiliza para mostrar las relaciones entre dos variables cuantitativas.
<br><br>
<strong>Los elementos que tiene son:</strong><br><br>
<strong>Eje X:</strong> Representa la variable independiente. <br>
<strong>Eje Y:</strong> Representa la variable dependiente. <br>
<strong>Puntos:</strong> Cada punto del diagrama representa un par de valores (uno para la variable independiente y otro para la variable dependiente) de los datos.
    </p>
</section>
<section>
    <h2>5.1.2 Regresión lineal simple</h2>
    <p>
        Es un modelo estadístico que se utiliza para modelar la relación lineal entre una variable dependiente (Y) y una variable independiente (X).
        <br><br><strong>La ecuación de la regresión lineal simple es:</strong>

        <strong>Y = α + β * X + ε</strong>
        
        <strong>Donde:</strong> <br><br>
        
<strong>Y</strong> es la variable dependiente. <br>
<strong>X</strong> es la variable independiente. <br>
<strong>α</strong> es el intercepto, que representa el valor de Y cuando X es 0.  <br>
<strong>β</strong> es la pendiente, que representa el cambio en Y por cada unidad de cambio en X. <br>
<strong>ε</strong> es el término de error, que representa la variabilidad aleatoria en la relación entre Y y X
    </p>
</section>

<section>
    <h2>5.1.3 Correlación</h2>
    <p>
        La correlación mide la fuerza y la dirección de la relación lineal entre dos variables, tiene como objetivo determinar si existe una relación entre dos variables y cuán fuerte es esa relación.
    </p>
</section>

<section>
    <h2>5.1.4 Determinación y análisis de los coeficientes de correlación y de determinación</h2>
    <p><strong>Un coeficiente de correlación</strong> es útil para identificar y medir la fuerza de la relación entre dos variables antes de realizar un análisis más profundo.</p><br>
    <p><strong>Un coeficiente de eeterminación</strong>es fundamental en la regresión para evaluar qué tan bien el modelo predice la variable dependiente y para comparar diferentes modelos de regresión.
    <br><br>
    Ambos coeficientes son esenciales en estadística para comprender y medir las relaciones entre variables y evaluar la eficacia de los modelos predictivos.
</p>
</section>
<section>
    <h2>5.1.5 Distribución normal bidimensional</h2>
    <p>
        La distribución normal bidimensional se generaliza a dos variables aleatorias y se conoce como distribución normal bidimensional. La probabilidad conjunta de que dos variables aleatorias continuas (X y Y) tomen valores específicos se describe en esta distribución.
<br>Es importante recordar que la distribución normal bidimensional es un modelo estadístico que asume que las variables siguen una distribución normal conjunta. Se deben considerar modelos alternativos si las variables no siguen esta distribución. Además, la inferencia causal basada en la correlación requiere un análisis minucioso y la consideración de los factores que podrían causar confusión. 
    </p>
</section>

<section>
    <h2>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlación</h2>
    <p>
        Las pruebas de coeficientes de correlación y los intervalos de confianza son técnicas cruciales para inferir propiedades de la población a partir de una muestra. Estos métodos ayudan a determinar si hay una correlación significativa entre dos variables y la precisión de la estimación.
        <br> <br>
<strong>Para calcular el coeficiente de correlación necesitamos:</strong><br><br>

    1. Calcular el coeficiente de correlación muestral (r) a partir de los datos de la muestra. <br>
    2. Determinar el tamaño de la muestra (n). <br>
    3. Encontrar el valor z crítico correspondiente al nivel de confianza deseado. <br>
    4. Calcular el error estándar del coeficiente de correlación.
    </p>
</section>
<section>
    <h2>5.1.7 Errores de medición</h2>
    <p>
        Son diferencias entre el valor medido de una cantidad y su valor verdadero. Estos errores son inevitablemente presentes en cualquier proceso de medición y pueden tener un impacto en la confiabilidad y precisión de los datos.
        <br><br>
        <strong>Algunos errores de medicion pueden ser:</strong>
        <strong>Errores sistemáticos:</strong> Son errores constantes que se producen por causas específicas, como la calibración incorrecta del instrumento de medición, defectos en el instrumento o errores en el método de medición. Estos errores tienden a afectar todas las mediciones de la misma manera y pueden ser corregidos identificando y eliminando la causa. <br>
        <strong>Errores aleatorios:</strong> Son errores variables que se producen por factores impredecibles, como las condiciones ambientales, la fatiga del observador o la naturaleza aleatoria del proceso que se está midiendo. Estos errores no pueden ser eliminados por completo, pero se pueden controlar y reducir su impacto mediante técnicas estadísticas.
    </p><br>
    <p>
        Los errores de medición son una parte inevitable de cualquier proceso de medición. Sin embargo, existen técnicas para minimizar su impacto y garantizar la confiabilidad de los datos.
    </p>
</section>







 <p> Author: Yael Antonio Chavez Atanacio</p>
</body>
</html>